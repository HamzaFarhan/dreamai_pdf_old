[
  {
    "objectID": "segment.html",
    "href": "segment.html",
    "title": "Segment",
    "section": "",
    "text": "source\n\nload_ner_model\n\n load_ner_model ()\n\n\nsource\n\n\nload_segs_model\n\n load_segs_model ()\n\n\nsource\n\n\nget_contact_dict\n\n get_contact_dict (text)\n\n\nsource\n\n\nget_job_dicts\n\n get_job_dicts (job, tagger)\n\n\nsource\n\n\nget_edu_dicts\n\n get_edu_dicts (edu, tagger)\n\n\nsource\n\n\nners_to_dicts\n\n ners_to_dicts (s, search_tags=['ORG', 'DATE'], dict_keys=['COMPANY',\n                'DATE'])\n\n\nsource\n\n\nsegment_to_ners\n\n segment_to_ners (text, tagger)\n\n\nsource\n\n\ntext_to_segments\n\n text_to_segments (text, labeling_model, segments={'education':\n                   ['bachelors'], 'work experience': ['employment']},\n                   keywords=[])\n\n\nsource\n\n\nget_lemma_dict\n\n get_lemma_dict (words)\n\n\nsource\n\n\nget_lemmas\n\n get_lemmas (word)\n\n\n# device = default_device()\n\n# segs_model = load_segs_model()\n# ner_model = load_ner_model()\n# cols_model = load_cols_model('../model/best_model.pth', device=device)\n\n\n# file = '../pdfs/test1.pdf'\n# pdf_text = pdf_to_text(file, model=cols_model)\n\n\n# pdf_text[file]\n\n\n# segs = text_to_segments(pdf_text[file], segs_model, segments={'education':['bachelors', 'college'],\n#                                                               'work experience':['employment']},\n#                         keywords=['skills', 'client'])\n\n\n# job_dicts = get_job_dicts(segs['work experience'], ner_model)\n# edu_dicts = get_edu_dicts(segs['education'], ner_model)\n\n\n# pprint(segs)\n\n\n# pprint(job_dicts)\n\n\n# pprint(edu_dicts)"
  },
  {
    "objectID": "parse.html",
    "href": "parse.html",
    "title": "Parse",
    "section": "",
    "text": "source\n\npred_cols\n\n pred_cols (pdf, model, classes=[1, 2, 3], device='cpu')\n\n\nsource\n\n\npdf_to_batch\n\n pdf_to_batch (pdf)\n\n\nsource\n\n\nload_cols_model\n\n load_cols_model (path, device='cpu')\n\n\nsource\n\n\ncreate_model\n\n create_model (num_classes=4, lin_ftrs=None, ps=0.5, concat_pool=True,\n               bn_final=False, lin_first=False, actv=None,\n               relu_fn=ReLU(inplace=True), trial=None, num_lin_ftrs=None,\n               n_lin_ftrs=None, trial_num_lin_ftrs=[1, 3],\n               trial_n_lin_ftrs=[256, 512, 1024])\n\n\nsource\n\n\ncreate_head\n\n create_head (nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True,\n              bn_final=False, lin_first=False, y_range=None, actv=None,\n              relu_fn=ReLU(inplace=True), trial=None, num_lin_ftrs=None,\n              n_lin_ftrs=None, trial_num_lin_ftrs=[1, 3],\n              trial_n_lin_ftrs=[256, 512, 1024])\n\nModel head that takes nf features, runs through lin_ftrs, and out n_out classes.\n\nsource\n\n\nAdaptiveConcatPool2d\n\n AdaptiveConcatPool2d (size=None)\n\nLayer that concats AdaptiveAvgPool2d and AdaptiveMaxPool2d\n\nsource\n\n\nFlatten\n\n Flatten (*args, **kwargs)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nLinBnDrop\n\n LinBnDrop (n_in, n_out, bn=True, p=0.0, act=None, lin_first=False)\n\nModule grouping BatchNorm1d, Dropout and Linear layers\n\nsource\n\n\nHeadModel\n\n HeadModel (pool, linear)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\npdf_to_text\n\n pdf_to_text (data_path, model=None, max_n_cols=3, cols_list=[2, 1],\n              device='cpu')\n\n\nsource\n\n\npdf_cols_to_text\n\n pdf_cols_to_text (pdf_cols)\n\n\nsource\n\n\npdf_to_cols\n\n pdf_to_cols (data_path, model=None, max_n_cols=3, cols_list=[2, 1],\n              device='cpu')\n\n\nsource\n\n\nget_n_cols\n\n get_n_cols (data, min_c=2, max_c=10, max_n_cols=3)\n\n/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n\nsource\n\n\nColumnCounter\n\n ColumnCounter (estimator, ax=None, k=10, metric='distortion',\n                distance_metric='euclidean', timings=True,\n                locate_elbow=True, **kwargs)\n\nThe K-Elbow Visualizer implements the “elbow” method of selecting the optimal number of clusters for K-means clustering. K-means is a simple unsupervised machine learning algorithm that groups data into a specified number (k) of clusters. Because the user must specify in advance what k to choose, the algorithm is somewhat naive – it assigns all members to k clusters even if that is not the right k for the dataset.\nThe elbow method runs k-means clustering on the dataset for a range of values for k (say from 1-10) and then for each value of k computes an average score for all clusters. By default, the distortion score is computed, the sum of square distances from each point to its assigned center. Other metrics can also be used such as the silhouette score, the mean silhouette coefficient for all samples or the calinski_harabasz score, which computes the ratio of dispersion between and within clusters.\nWhen these overall metrics for each model are plotted, it is possible to visually determine the best value for k. If the line chart looks like an arm, then the “elbow” (the point of inflection on the curve) is the best value of k. The “arm” can be either up or down, but if there is a strong inflection point, it is a good indication that the underlying model fits best at that point.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\na scikit-learn clusterer\n\nShould be an instance of an unfitted clusterer, specifically KMeans orMiniBatchKMeans. If it is not a clusterer, an exception is raised.\n\n\nax\nNoneType\nNone\nThe axes to plot the figure on. If None is passed in the current axeswill be used (or generated if required).\n\n\nk\nint\n10\nThe k values to compute silhouette scores for. If a single integeris specified, then will compute the range (2,k). If a tuple of 2integers is specified, then k will be in np.arange(k[0], k[1]).Otherwise, specify an iterable of integers to use as values for k.\n\n\nmetric\nstr\ndistortion\nSelect the scoring metric to evaluate the clusters. The default is themean distortion, defined by the sum of squared distances between eachobservation and its closest centroid. Other metrics include:- distortion: mean sum of squared distances to centers- silhouette: mean ratio of intra-cluster and nearest-cluster distance- calinski_harabasz: ratio of within to between cluster dispersion\n\n\ndistance_metric\nstr\neuclidean\nThe metric to use when calculating distance between instances in afeature array. If metric is a string, it must be one of the options allowedby sklearn’s metrics.pairwise.pairwise_distances. If X is the distance array itself,use metric=“precomputed”.\n\n\ntimings\nbool\nTrue\nDisplay the fitting time per k to evaluate the amount of time requiredto train the clustering model.\n\n\nlocate_elbow\nbool\nTrue\nAutomatically find the “elbow” or “knee” which likely corresponds to the optimalvalue of k using the “knee point detection algorithm”. The knee point detectionalgorithm finds the point of maximum curvature, which in a well-behavedclustering problem also represents the pivot of the elbow curve. The point islabeled with a dashed line and annotated with the score and k values.\n\n\nkwargs\ndict\n\nKeyword arguments that are passed to the base class and may influencethe visualization as defined in other Visualizers.\n\n\n\n\nsource\n\n\ncol_clusters\n\n col_clusters (data, data2=None, n_cols=3)"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core",
    "section": "",
    "text": "source\n\ncolor_fill_pdf_text\n\n color_fill_pdf_text (pdf, height=512, color='black')\n\nGets a pdf and returns a list of images with the text filled in with the specified color.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npdf\n\n\n\n\n\nheight\nint\n512\n\n\n\ncolor\nstr\nblack\n\n\n\nReturns\nlist\n\nA list of np.ndarray images.\n\n\n\n\nsource\n\n\nonly_bnw\n\n only_bnw (img, thresh=50)\n\n\nsource\n\n\nprocess_text\n\n process_text (text)\n\n\nsource\n\n\nsplit_words\n\n split_words (words, key0='top', key1='bottom', avg_gap=None,\n              fill_empty=False)\n\n\nsource\n\n\ncombine_splits\n\n combine_splits (splits)\n\n\nsource\n\n\nget_max_gap\n\n get_max_gap (words, key0='top', key1='bottom')\n\n\nsource\n\n\nget_avg_gap\n\n get_avg_gap (words, key0='top', key1='bottom')\n\n\nsource\n\n\ncombine_lines\n\n combine_lines (txt)\n\n\nsource\n\n\ncid_to_char\n\n cid_to_char (cidx)\n\n\nsource\n\n\npdf_img_to_np\n\n pdf_img_to_np (img)\n\n\nsource\n\n\nload_pdf\n\n load_pdf (pdf)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dreamai_pdf",
    "section": "",
    "text": "pip install dreamai_pdf"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "dreamai_pdf",
    "section": "",
    "text": "pip install dreamai_pdf"
  }
]