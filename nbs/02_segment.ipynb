{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hamza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "from dreamai_pdf.core import *\n",
    "from dreamai_pdf.parse import *\n",
    "from dreamai_pdf.imports import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_lemmas(word):\n",
    "    # print(word)\n",
    "    forms = {word}\n",
    "    for happy_lemma in wordnet.lemmas(word):\n",
    "        forms.add(happy_lemma.name().lower())\n",
    "        for related_lemma in happy_lemma.derivationally_related_forms():\n",
    "            forms.add(related_lemma.name().lower())\n",
    "    # print(forms)\n",
    "    return list(forms)\n",
    "\n",
    "def get_lemma_dict(words):\n",
    "    if is_list(words):\n",
    "        words = {w:[] for w in words}\n",
    "    words = {k:v+[k] for k,v in words.items()}\n",
    "    return {lem:k for k,v in words.items() for lem in flatten_list([get_lemmas(x) for x in v])}\n",
    "\n",
    "def text_to_segments(text, labeling_model, segments={'education':['bachelors'], 'work experience':['employment']}, keywords=[]):\n",
    "    seg_ld = get_lemma_dict(segments)\n",
    "    kw_ld = get_lemma_dict(keywords)\n",
    "    seg_lems = list_map(dict_keys(seg_ld), str.lower)\n",
    "    segs = defaultdict(list)\n",
    "    for txt in text:\n",
    "        pred = seg_lems[labeling_model(txt.lower(), seg_lems)[0][0]]\n",
    "        segs[seg_ld[pred]].append(txt)\n",
    "        for kw_lem, kw in kw_ld.items():\n",
    "            if kw_lem.lower() in txt.lower() and txt not in segs[kw]:\n",
    "                segs[kw].append(txt)\n",
    "    return segs\n",
    "\n",
    "def segment_to_ners(text, tagger):\n",
    "    if is_list(text):\n",
    "        text = ' '.join(text)\n",
    "    s = Sentence(text)\n",
    "    tagger.predict(s)\n",
    "    return s\n",
    "\n",
    "def ners_to_dicts(s, search_tags=['ORG', 'DATE'], dict_keys=['COMPANY', 'DATE']):\n",
    "    tags_list = []\n",
    "    tags_dict = {}\n",
    "    for l in s.labels:\n",
    "        dp = l.data_point\n",
    "        tag = dp.tag\n",
    "        for s,k in zip(search_tags, dict_keys):\n",
    "            if tag == s:\n",
    "                if not tags_dict.get(k,None):\n",
    "                    tags_dict[k] = dp.text.strip()\n",
    "                else:\n",
    "                    tags_list.append(tags_dict)\n",
    "                    tags_dict = {k:dp.text.strip()}\n",
    "                \n",
    "    return tags_list\n",
    "\n",
    "def get_edu_dicts(edu, tagger):\n",
    "    edu = segment_to_ners(edu, tagger)\n",
    "    edu_list = ners_to_dicts(edu, search_tags=['ORG', 'DATE'], dict_keys=['INSTITUTE', 'DATE'])\n",
    "    edu_list = [d for d in edu_list if d.get('INSTITUTE', None) is not None]\n",
    "    return edu_list\n",
    "\n",
    "def get_job_dicts(job, tagger):\n",
    "    job = segment_to_ners(job, tagger)\n",
    "    job_dict = ners_to_dicts(job, search_tags=['ORG', 'DATE'], dict_keys=['COMPANY', 'DATE'])\n",
    "    job_dict = [d for d in job_dict if d.get('COMPANY', None) is not None]\n",
    "    return job_dict\n",
    "\n",
    "def get_contact_dict(text):\n",
    "    if is_list(text): text = ' '.join(text)\n",
    "    mail_regex = re.compile(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
    "    phone_regex = re.compile(r'[\\d]{3}[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}')\n",
    "    emails = re.findall(mail_regex, text.lower())\n",
    "    phones = re.findall(phone_regex, text.lower())\n",
    "    return {'EMAIL':emails, 'PHONE':phones}\n",
    "\n",
    "def load_segs_model():\n",
    "    return Labels(\"roberta-large-mnli\")\n",
    "\n",
    "def load_ner_model():\n",
    "    return Classifier.load('ner-ontonotes-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = default_device()\n",
    "\n",
    "# segs_model = load_segs_model()\n",
    "# ner_model = load_ner_model()\n",
    "# cols_model = load_cols_model('../model/best_model.pth', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '../pdfs/test1.pdf'\n",
    "# pdf_text = pdf_to_text(file, model=cols_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_text[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segs = text_to_segments(pdf_text[file], segs_model, segments={'education':['bachelors', 'college'],\n",
    "#                                                               'work experience':['employment']},\n",
    "#                         keywords=['skills', 'client'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_dicts = get_job_dicts(segs['work experience'], ner_model)\n",
    "# edu_dicts = get_edu_dicts(segs['education'], ner_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(job_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(edu_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
